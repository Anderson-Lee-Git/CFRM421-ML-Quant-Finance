{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "We have five raw datasets, each of which comes in different formats. The goal of this section is to prepare the datasets into a unified `DataFrame` with features needed by feature extraction and the same dates. Standardization and pipeline preprocessing would be in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AAPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2512, 6)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl = pd.read_csv('../raw_data/AAPL.csv')\n",
    "\n",
    "# Target the time frame: 2013/05/06 - 2023/04/26\n",
    "aapl = aapl[(aapl['Date'] >= '2013-05-06') & (aapl['Date'] <= '2023-04-26')]\n",
    "\n",
    "# Get target features \n",
    "aapl_features = aapl[['Date', 'Open', 'Close', 'High', 'Low', 'Volume']]\n",
    "aapl_features.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Macroeconomic Variables\n",
    "\n",
    "### US Treasury Bill Bond (13 Weeks)\n",
    "\n",
    "- Typical Price of US Treasury Bill Bond (13 Weeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2512, 2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "def get_typical_price(X): \n",
    "    return np.average(X, axis=1)\n",
    "\n",
    "risk_free = pd.read_csv('../raw_data/US_Treasury_Bond_13weeks.csv')\n",
    "risk_free = risk_free.dropna()\n",
    "risk_free = risk_free[risk_free['Date'] >= '2013-05-06']\n",
    "transformer = FunctionTransformer(get_typical_price)\n",
    "typical_price = transformer.fit_transform(risk_free[['High', 'Close', 'Low']])\n",
    "risk_free = pd.DataFrame({\n",
    "    'Date': risk_free['Date'], \n",
    "    'Typical Price': typical_price\n",
    "})\n",
    "risk_free.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S&P 500 Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2512, 2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp500 = pd.read_csv('../raw_data/sp500_index.csv')\n",
    "sp500 = sp500[sp500['Date'] <= '2023-04-26']\n",
    "sp500.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fundamentals"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valuation measures\n",
    "- PeRatio: Share price over earnings per share\n",
    "- PsRatio: Share price over sales per share\n",
    "- PbRatio: Share price over book per share\n",
    "- Enterprise value to revenue ratio \n",
    "- Enterprise value to EDITDA(Earnings Before Interest, Taxes, Depreciation, and Amortization) ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2512, 2)\n",
      "(2512, 2)\n",
      "(2512, 2)\n",
      "(2512, 2)\n",
      "(2512, 2)\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "val_measure = pd.read_csv('../raw_data/AAPL_quarterly_valuation_measures.csv')\n",
    "# print(val_measure.columns)\n",
    "peratio = val_measure[val_measure.name == 'PeRatio'].drop(columns=['ttm', 'name'])\n",
    "psratio = val_measure[val_measure.name == 'PsRatio'].drop(columns=['ttm', 'name'])\n",
    "pbratio = val_measure[val_measure.name == 'PbRatio'].drop(columns=['ttm', 'name'])\n",
    "enterprise_val_revenue_ratio = val_measure[val_measure.name == 'EnterprisesValueRevenueRatio'].drop(columns=['ttm', 'name'])\n",
    "enterprise_val_ebitda_ratio = val_measure[val_measure.name == 'EnterprisesValueEBITDARatio'].drop(columns=['ttm', 'name'])\n",
    "feats = [peratio, psratio, pbratio, enterprise_val_revenue_ratio, enterprise_val_ebitda_ratio]\n",
    "names = ['PeRatio', 'PsRatio', 'PbRatio', 'EnterpriseValueRevenueRatio', 'EnterpriseValueEDITDARatio']\n",
    "dates = sp500.Date \n",
    "\n",
    "def quarterly_to_daily(quarter_data, dates, name):\n",
    "    target_date = []\n",
    "    for d in dates: \n",
    "        target_date.append(np.max(quarter_data.columns[quarter_data.columns <= d]))\n",
    "    daily_data = np.zeros(dates.shape[0])\n",
    "    for i, d in enumerate(target_date): \n",
    "        daily_data[i] = quarter_data[d]\n",
    "    return pd.DataFrame({\n",
    "        'Date': dates,\n",
    "        name: daily_data\n",
    "    })\n",
    "\n",
    "def transform_date_format(X): \n",
    "    '''\n",
    "    Transform the date format of input data's columns to format yyyy-mm-dd\n",
    "\n",
    "    Args: \n",
    "        X: pd.DataFrame where the columns should be quarterly dates in the format mm/dd/yyyy\n",
    "    Returns: \n",
    "        X_transformed: pd.DataFrame where the columns would be quarterly dates in the format yyyy-mm-dd\n",
    "    '''\n",
    "    dates = []\n",
    "    for d in X.columns: \n",
    "        date_obj = datetime.strptime(d, '%m/%d/%Y')\n",
    "        dates.append(date_obj.strftime('%Y-%m-%d'))\n",
    "    X_transformed = pd.DataFrame(X.values, columns=dates)\n",
    "    return X_transformed\n",
    "\n",
    "for i, feat in enumerate(feats): \n",
    "    feats[i] = quarterly_to_daily(transform_date_format(feat), dates, names[i])\n",
    "\n",
    "for i, feat in enumerate(feats): \n",
    "    print(feats[i].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Financials\n",
    "\n",
    "- BasicEPS: Earning Per Share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2512, 2)\n"
     ]
    }
   ],
   "source": [
    "dates = sp500.Date \n",
    "fin_measure = pd.read_csv('../raw_data/AAPL_quarterly_financials.csv')\n",
    "# print(fin_measure.columns)\n",
    "eps = fin_measure[fin_measure.name == 'BasicEPS'].drop(columns=['ttm', 'name'])\n",
    "eps = quarterly_to_daily(transform_date_format(eps), dates, 'BasicEPS')\n",
    "print(eps.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate all basic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_data = pd.merge(aapl_features, sp500, on='Date')\n",
    "for f in feats: \n",
    "    joined_data = pd.merge(joined_data, f, on='Date')\n",
    "joined_data = pd.merge(joined_data, eps, on='Date')\n",
    "joined_data.to_csv('../prepared_data/data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
